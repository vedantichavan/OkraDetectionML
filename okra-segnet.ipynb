{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9869213,"sourceType":"datasetVersion","datasetId":6058107}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\n# Set dataset path\nDATASET_PATH = '/kaggle/input/okradatasetfreshnessdetection'  # Replace with your dataset path\nIMAGE_SIZE = (128, 128)\nBATCH_SIZE = 32\n\n# Data Preparation\n\n# Define paths for classes\nadequate_path = '/kaggle/input/okradatasetfreshnessdetection/AdequateMature'\novermature_path = '/kaggle/input/okradatasetfreshnessdetection/OverMature'\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:30:29.119437Z","iopub.execute_input":"2025-01-06T06:30:29.119879Z","iopub.status.idle":"2025-01-06T06:30:29.127776Z","shell.execute_reply.started":"2025-01-06T06:30:29.119838Z","shell.execute_reply":"2025-01-06T06:30:29.126057Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load images and labels\ndef load_images_and_labels(folder, label):\n    images = []\n    labels = []\n    for filename in os.listdir(folder):\n        img = load_img (os.path.join(folder, filename), target_size=IMAGE_SIZE)\n        if img is not None:\n            images.append(img_to_array(img))\n            labels.append(label)\n    return np.array(images), np.array(labels)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:33:07.531947Z","iopub.execute_input":"2025-01-06T06:33:07.532396Z","iopub.status.idle":"2025-01-06T06:33:07.539014Z","shell.execute_reply.started":"2025-01-06T06:33:07.532353Z","shell.execute_reply":"2025-01-06T06:33:07.537613Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Load both classes\nadequate_images, adequate_labels = load_images_and_labels(adequate_path, 0)\novermature_images, overmature_labels = load_images_and_labels(overmature_path, 1)\n\n# Combine data\nimages = np.concatenate([adequate_images, overmature_images])\nlabels = np.concatenate([adequate_labels, overmature_labels])\n\n# Normalize images\nimages = images / 255.0\n\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:33:10.541591Z","iopub.execute_input":"2025-01-06T06:33:10.541997Z","iopub.status.idle":"2025-01-06T06:33:10.602622Z","shell.execute_reply.started":"2025-01-06T06:33:10.541961Z","shell.execute_reply":"2025-01-06T06:33:10.600639Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load both classes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m adequate_images, adequate_labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_images_and_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43madequate_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m overmature_images, overmature_labels \u001b[38;5;241m=\u001b[39m load_images_and_labels(overmature_path, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Combine data\u001b[39;00m\n","Cell \u001b[0;32mIn[9], line 6\u001b[0m, in \u001b[0;36mload_images_and_labels\u001b[0;34m(folder, label)\u001b[0m\n\u001b[1;32m      4\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder):\n\u001b[0;32m----> 6\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mload_images_and_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIMAGE_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m         images\u001b[38;5;241m.\u001b[39mappend(img_to_array(img))\n","\u001b[0;31mTypeError\u001b[0m: load_images_and_labels() got an unexpected keyword argument 'target_size'"],"ename":"TypeError","evalue":"load_images_and_labels() got an unexpected keyword argument 'target_size'","output_type":"error"}],"execution_count":10},{"cell_type":"code","source":"# Data Augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build Classification Model\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    epochs=50,\n    validation_data=(X_test, y_test),\n    verbose=1\n)\n\n# Evaluate the model\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n\n# Plot Training History\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy')\nplt.legend()\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Define a function to test and display a single image\ndef test_single_image(index, X_test, y_test, model):\n    # Select the image and true label\n    image = X_test[index]\n    true_label = y_test[index]  # Since labels are 0 or 1, we directly use them\n    \n    # Add batch dimension for prediction\n    image_batch = np.expand_dims(image, axis=0)\n    \n    # Predict the class probability\n    predicted_prob = model.predict(image_batch)\n    predicted_label = (predicted_prob >= 0.5).astype(int)  # Convert probability to binary class\n    \n    # Display the image\n    plt.imshow(image)\n    plt.title(f\"True Label: {'Adequate' if true_label == 0 else 'Overmature'} | \"\n              f\"Predicted Label: {'Adequate' if predicted_label == 0 else 'Overmature'}\")\n    plt.axis('off')\n    plt.show()\n    \n    # Print the confidence score for the \"Overmature\" class\n    print(f\"Confidence Score (Overmature): {predicted_prob[0][0]:.4f}\")\n\n# Example usage: Test and display the 38th image in the test set\ntest_single_image(38, X_test, y_test, model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:30:10.109335Z","iopub.status.idle":"2025-01-06T06:30:10.109796Z","shell.execute_reply.started":"2025-01-06T06:30:10.109590Z","shell.execute_reply":"2025-01-06T06:30:10.109613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}